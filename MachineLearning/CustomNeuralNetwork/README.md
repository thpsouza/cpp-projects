# CustomNeuralNetwork Framework

A C++ neural network framework built from scratch using the LinearAlgebra library.

## Features

- **Neural Network Class** - Configurable feedforward network
  - Flexible architecture design
  - Forward pass computation
  - Backward pass with gradient computation

- **Activation Functions**
  - ReLU (Rectified Linear Unit)
  - Sigmoid
  - Tanh

- **Loss Functions**
  - Mean Squared Error (MSE)

- **Optimizers**
  - Stochastic Gradient Descent (SGD)

- **Benchmarking Tools** - In-built performance measurement utilities


## ğŸ“ Project Structure

```
CustomNeuralNetwork/
â”œâ”€â”€ README.md
â”œâ”€â”€ include/
â”‚   â””â”€â”€ CustomNeuralNetwork/
â”‚       â”œâ”€â”€ NN.h
â”‚       â”œâ”€â”€ DenseLayer.h
â”‚       â”œâ”€â”€ ActivationFunctions/
â”‚       â”‚   â”œâ”€â”€ ActivationFunctions.h
â”‚       â”‚   â”œâ”€â”€ BaseActivationFunction.h
â”‚       â”‚   â”œâ”€â”€ ReLUActivationFunction.h
â”‚       â”‚   â”œâ”€â”€ SigmoidActivationFunction.h
â”‚       â”‚   â””â”€â”€ TanhActivationFunction.h
â”‚       â”œâ”€â”€ LossFunctions/
â”‚       â”‚   â”œâ”€â”€ LossFunctions.h
â”‚       â”‚   â”œâ”€â”€ BaseLossFunction.h
â”‚       â”‚   â””â”€â”€ MeanSquaredErrorLossFunction.h
â”‚       â””â”€â”€ Optimizers/
â”‚           â”œâ”€â”€ Optimizers.h
â”‚           â”œâ”€â”€ BaseOptimizer.h
â”‚           â””â”€â”€ StochasticGDOptimizer.h
â””â”€â”€ src/
    â”œâ”€â”€ NN.cpp
    â”œâ”€â”€ DenseLayer.cpp
    â”œâ”€â”€ ActivationFunctions/
    â”‚   â”œâ”€â”€ BaseActivationFunction.cpp
    â”‚   â”œâ”€â”€ ReLUActivationFunction.cpp
    â”‚   â”œâ”€â”€ SigmoidActivationFunction.cpp
    â”‚   â””â”€â”€ TanhActivationFunction.cpp
    â”œâ”€â”€ LossFunctions/
    â”‚   â”œâ”€â”€ BaseLossFunction.cpp
    â”‚   â””â”€â”€ MeanSquaredErrorLossFunction.cpp
    â””â”€â”€ Optimizers/
        â”œâ”€â”€ BaseOptimizer.cpp
        â””â”€â”€ StochasticGDOptimizer.cpp
```


## Building

Manual compilation:

```powershell
clang++.exe -std=c++20 -c 
-I./CustomNeuralNetwork/include 
MachineLearning/CustomNeuralNetwork/src/**.cpp 
MachineLearning/CustomNeuralNetwork/src/ActivationFunctions/**.cpp 
MachineLearning/CustomNeuralNetwork/src/LossFunctions/**.cpp 
MachineLearning/CustomNeuralNetwork/src/Optimizers/**.cpp 
main.cpp -o main.exe
```

CMake:

```bash
mkdir build && cd build
cmake ..
cmake --build . --config Release
```


## Dependencies

- **LinearAlgebra** - Custom linear algebra library from parent directory


## ğŸ¯ Current Limitations

- âš ï¸ No batch normalization
- âš ï¸ No regularization (L1/L2)
- âš ï¸ Limited optimizer support


## Future Enhancements

- [ ] Batch normalization
- [ ] Dropout regularization
- [ ] More optimizers (Adam, RMSprop)
- [ ] Convolutional layers
- [ ] Recurrent layers
- [ ] GPU acceleration
